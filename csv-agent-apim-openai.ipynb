{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain with APIM fronting Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_endpoint = \"YOUR_OPENAI_ENDPOINT\"\n",
    "openai_key = \"YOUR_OPENAI_KEY\"\n",
    "apim_endpoint = \"YOUR_APIM_ENDPOINT\"\n",
    "apim_key = \"YOUR_APIM_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple query to Azure OpenAI directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import openai\n",
    "\n",
    "# Initialize the LangChain agent with Azure OpenAI  \n",
    "openai.api_key = openai_key  \n",
    "openai.api_base =  openai_endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2024-06-01\"\n",
    "\n",
    "deployment_name = \"gpt-4o\"\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=openai.api_key,  \n",
    "    azure_endpoint=openai.api_base,  \n",
    "    api_version=openai.api_version, \n",
    "    deployment_name=deployment_name,\n",
    "    temperature=0.3\n",
    "    )\n",
    "\n",
    "# Define a function to send a prompt to the agent and get a response\n",
    "def ask_agent(prompt):\n",
    "    human_message = HumanMessage(content=prompt)\n",
    "    response = llm.invoke([human_message])\n",
    "    return response\n",
    "\n",
    "# Send a simple prompt to the agent\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = ask_agent(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple query but via APIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import openai\n",
    "\n",
    "# Initialize the LangChain agent with Azure OpenAI, but using the APIM endpoint  \n",
    "openai.api_key = apim_key  \n",
    "openai.api_base = apim_endpoint  \n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2024-06-01\"\n",
    "\n",
    "deployment_name = \"gpt-4o\"\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=openai.api_key,  \n",
    "    azure_endpoint=openai.api_base,  \n",
    "    api_version=openai.api_version, \n",
    "    deployment_name=deployment_name,\n",
    "    temperature=0.3\n",
    "    )\n",
    "\n",
    "# Define a function to send a prompt to the agent and get a response\n",
    "def ask_agent(prompt):\n",
    "    human_message = HumanMessage(content=prompt)\n",
    "    response = llm.invoke([human_message])\n",
    "    return response\n",
    "\n",
    "# Send a simple prompt to the agent\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = ask_agent(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now a Pandas version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.agents import AgentType\n",
    "from langchain import OpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "# Load the \"titanic.csv\" dataset\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# Initialize the LangChain agent with Azure OpenAI, but using the APIM endpoint  \n",
    "openai.api_key = apim_key  \n",
    "openai.api_base = apim_endpoint  \n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2024-06-01\"\n",
    "\n",
    "deployment_name = \"gpt-4o\"\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=openai.api_key,  \n",
    "    azure_endpoint=openai.api_base,  \n",
    "    api_version=openai.api_version, \n",
    "    deployment_name=deployment_name,\n",
    "    temperature=0.3\n",
    "    )\n",
    "\n",
    "# Define a function to ask the agent a question about the DataFrame\n",
    "def ask_agent(question):\n",
    "    system_message = SystemMessage(content=f\"You are working with a pandas dataframe in Python. The name of the dataframe is `df`.\\nThis is the result of `print(df.head())`:\\n{df.head().to_string()}\")\n",
    "    human_message = HumanMessage(content=question)\n",
    "    response = llm.invoke([system_message, human_message])\n",
    "    return response\n",
    "\n",
    "# Ask the agent \"How many rows are in the DataFrame?\"\n",
    "question = \"what's the average age of survivors\"\n",
    "response = ask_agent(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A better version direct to Azure OpenAI\n",
    "This looks a better version from here https://api.python.langchain.com/en/latest/agents/langchain_experimental.agents.agent_toolkits.pandas.base.create_pandas_dataframe_agent.html , but still has issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# initialize the LangChain agent with OpenAI\n",
    "openai.api_key = openai_key  \n",
    "openai.api_base =  openai_endpoint  \n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2024-06-01\"\n",
    "\n",
    "deployment_name = \"gpt-4o\"\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=openai.api_key,  \n",
    "    azure_endpoint=openai.api_base,  \n",
    "    api_version=openai.api_version, \n",
    "    deployment_name=deployment_name,\n",
    "    temperature=0.3\n",
    "    )\n",
    "\n",
    "agent_executor = create_pandas_dataframe_agent(\n",
    "    llm,\n",
    "    df,\n",
    "    agent_type=\"tool-calling\",\n",
    "    verbose=True,\n",
    "    allow_dangerous_code=True\n",
    ")\n",
    "\n",
    "agent_executor.invoke({\"input\": \"what's the average age of survivors\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with APIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# Initialize the LangChain agent with Azure OpenAI, but using the APIM endpoint  \n",
    "openai.api_key = apim_key  \n",
    "openai.api_base = apim_endpoint \n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2024-06-01\"\n",
    "\n",
    "deployment_name = \"gpt-4o\"\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=openai.api_key,  \n",
    "    azure_endpoint=openai.api_base,  \n",
    "    api_version=openai.api_version, \n",
    "    deployment_name=deployment_name,\n",
    "    temperature=0.3\n",
    "    )\n",
    "\n",
    "agent_executor = create_pandas_dataframe_agent(\n",
    "    llm,\n",
    "    df,\n",
    "    agent_type=\"tool-calling\",\n",
    "    verbose=True,\n",
    "    allow_dangerous_code=True\n",
    ")\n",
    "\n",
    "agent_executor.invoke({\"input\": \"what's the average age of survivors\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
